This chapter provides an overview of \acfp{ANN}, synchronous programming and \acf{RE}.
This chapter starts with an introduction on \acp{ANN}, their structure and their value in \acp{CPS}.
The aim is to provide a general understanding to the functionality of \acp{ANN} and their safety regarding \acp{CPS}.
The next section briefly introduces synchronous programming, and highlights Esterel as the language of choice for this thesis. 
And example of an Esterel program is given, with a quick run-down of how it functions and its syntax.
Finally, \ac{RE} is introduced as a safety mechanism for \acp{CPS}.
A brief background to \ac{RE} and its combination with \acp{ANN} is discussed.

\section{Artificial Neural Networks}
\subsection{Machine Learning}
\acp{ANN} were originally proposed to mimic the functioning of  biological neural networks~\cite{kohonen1988introduction}, which produce recurrent spatio temporal patterns~\cite{rolston2007precisely}. 
Similar timed activity of neurons in the cerebellum has been reported in~\cite{bullock1994neural, moore1989adaptively}. 
A number of types of \ac{NN} which mimic their biological counterparts exist, varying in complexity and accuracy, including the \ac{SNN}~\cite{izhikevich2003spiking,maass1997spiking}, which was designed to model the brain and has been demonstrated to be periodic and run with discrete time intervals when implemented in software. 
\acp{ANN} are also part of deep learning; \acfp{CNN}~\cite{schmidhuber2015deep} were introduced with many more layers than is possible on a \ac{MLP}. 
\acp{CNN}, are widely used in \ac{CPS} applications such as autonomous vehicles, e.g. in \cite{EndToEndLearningForSelfDrivingCars}, where a \ac{CNN} is trained to map raw pixel data directly to vehicle steering commands.

\subsection{Structure of an Artificial Neural Network}
Most \acp{ANN} do not feature such complex models like those of spiking neural networks, as they are more difficult to use, implement, and train. 
Instead, they rely on simpler networks, which can be considered as \emph{un-timed non-linear} functions, where the outputs change relative to the inputs, but the timing of the change is not precisely defined. 
An example of such a network is provided in Figure~\ref{fig:mlp-ann}, which is using neurons defined in Figure~\ref{fig:artificial-neuron}. 
This is a type of \ac{ANN} known as an \acf{MLP}~\cite{yegnanarayana1994artificial}.
A \ac{MLP} consists of interconnected layers of artificial neurons, each neuron providing input to neurons in the next layer.

Specialised neural networks, called \acfp{RNN}~\cite{medsker2001recurrent}, were introduced to classify temporal sequences. 
These operate in a step by step manner, where the operation in the current time step relies on the context from some previous step.

\acp{CNN} were introduced to classify complex, 3-D inputs such as images.
These are similar to \acp{ANN} such that they are composed of multiple layers, each providing inputs to the following layer. 
However, \acp{CNN} have more complex neurons than \acp{MLP}, with varying types of layers such as convolutional layers, pooling layers and dense layers.
A figure of a \ac{CNN} is provided in Figure~\ref{fig:cnn}.

\begin{figure}
	\centering
	\scalebox{0.8}{\input{Content/fig/mlp-ann.tex}}
	\caption{Example \ac{MLP} \ac{ANN}.	\label{fig:mlp-ann}}
\end{figure}
\begin{figure}
	\centering
	\scalebox{0.8}{\input{Content/fig/neuron.tex}}
	\caption{A model of an artificial neuron. \label{fig:artificial-neuron}}
\end{figure}
\begin{figure}
	\centering
	\includegraphics[width=\textwidth]{Content/fig/cnn-img.pdf}
	\caption{Example \ac{CNN} \label{fig:cnn}}
\end{figure}

\acp{ANN} are being increasingly used as controllers in \acp{CPS} due to their ability to learn data relationships in ways that are difficult to replicate~\cite{ANNSafety2007}. 
\acp{ANN} can deal with novel inputs to the system and are able to outperform other forms of \ac{AI} at computational efficiency, pattern recognition, function approximation and image identification~\cite{AIComp2016, AIComp2017}. 
However, it can be very difficult to ensure the safety of a system involving \acp{ANN}~\cite{ANNSafety2007, ANNSafety2018}.

\subsection{Artificial Neural Networks for \ac{CPS}}
In order for an \ac{ANN} to be used in any capacity within a system where safety is critical, it should undergo rigorous and thorough validation, verification, and testing procedures to ensure that they it is sufficiently safe for its target system~\cite{scann, ANNSafetyLifecycle2003}. 

While considerable research effort is starting in the direction of formal verification of \ac{AI}-based \ac{CPS}~\cite{seshia2016towards, russell2015}, the issue of timing verification has received scant attention. 
Like the challenges involving functional verification, timing verification of AI-based  \ac{CPS} poses considerable challenges due to: (1) real-time \ac{AI} systems could involve many concurrent and interacting \ac{AI} modules, which need deterministic composition for safety; (2) \ac{AI} modules are usually developed as untimed systems and the reactive nature of AI algorithms used in CPS are not carefully studied; and (3) \acf{WCET} analysis~\cite{wilhelm2008worst} of \ac{AI}-based \ac{CPS} has received scant attention.

Definitions for this safety vary, but Kurd et. al.~\cite{EstSafeCriteria2003} provide a generalisation: safe \acp{ANN} can be defined as those that:
\begin{itemize}
	\item tolerate faults and inconsistencies in their inputs,
	\item do not create hazardous outputs,
	\item behave in a predictable and repeatable manner,
	\item and are trained on clean, reliable data. 
\end{itemize}

To achieve these properties, there exist safety measures such as risk management systems that span the entire development process of the \ac{ANN}~\cite{ANNDevModel1999} and standards with which \acp{ANN} can be certified before they are used in systems where safety is critical~\cite{SCANNStandard}. 
These techniques are primarily \textit{proactive} in nature, producing \acp{ANN} that are classified as \textit{safe enough} for their role. 

However, as \acp{ANN} become larger and more full-featured, they  become harder to statically analyse.
Problematic situations can arise when an \ac{ANN} exhibits unexpected behaviour that the system is unable to safely respond to, and in \ac{CPS} these situations can be life threatening.

\subsection{Static Verification of \acp{ANN}}
There are a variety of pre-existing methods for statically checking the correctness of autonomous (i.e. artificially intelligent) systems.
For instance, model checking on systems that use timed automata~\cite{timed-enf-autonomous}.
Okano et. al. explore the concept of model checking of autonomous systems that use timed automata~\cite{timed-enf-autonomous}. 
This technique is a static technique and cannot be applied to autonomous \ac{ANN} systems, where the behaviour of the \ac{ANN} controller cannot be defined by an automaton.
For an autonomous system that includes at least one \ac{ANN} in its controller, novel techniques are required to guarantee the safety properties of the \acp{ANN}
However, \acp{ANN} are not usually able to be simplified to simple automata.

Verification of \ac{ANN}, specifically, Deep Neural Networks, can be performed for certain properties (such as robustness) using \ac{SMT}~\cite{Gehr2018AI2SA,reluplex,DeepANNverify}.
This is useful, because the robustness of a deep \ac{ANN} is critical property to its safety.
A robust \ac{ANN} is one that will provide consistently accurate outputs even when the input to the \ac{ANN} is noisy, incorrectly coloured or otherwise distorted. 
However, this approach is not flawless. 
\ac{SMT} has issues with scale: as the \acp{ANN} to analyse become larger, analysis time grows exponentially~\cite{Gehr2018AI2SA}.
Ergo, they are less efficient on larger deep \acp{ANN}.
In addition, they require the deep \acp{ANN} to fulfil some specific properties, such as specific activation functions and specific \ac{ANN} variants, i.e. \cite{Gehr2018AI2SA} only allows \acp{CNN} and \acp{MLP} with \ac{ReLU} activation functions.
This limits flexibility, as each \ac{ANN} must be designed around these restrictions, thus limiting properties of the \ac{ANN}, such as its activation function and size, could result in an \ac{ANN} that is inefficient, not robust, slow, etc.

Manual testing is a simple method to check for the correctness of an \ac{ANN}-based system. 
However, this is a time-consuming and error-prone process.
It is very difficult to ensure that tests have acceptable coverage of all possible situations~\cite{ANN-test}.

Finally, no matter the chosen methodology, as \acp{ANN} increase in size and complexity, verification and validation of these networks becomes increasingly more difficult to achieve~\cite{Gehr2018AI2SA}.




\section{Synchronous Languages}
Synchronous languages include a variety of different languages, some notable examples being Esterel, Lustre and Signal~\cite{benveniste2003synchronous}.
When it comes to validating and implementing real-time, embedded software, synchronous languages are the most design friendly and formally sound.

Synchronous languages abide to a set of semantics, that is that they support functional concurrency, have a simple formal model and support synchrony models.
To support synchrony and concurrency, synchronous languages divide time into discrete instants according to a logical clock.
Each logical tick, the system samples the inputs, takes some action and then emits the outputs.

\subsection{Esterel}
Esterel is one such synchronous language, created by GÃ©rard Berry in 1991~\cite{berry1991}. 
Esterel uses a collection of concurrently running threads synchronised to a single, global clock.
Pause statements are used to pause the thread execution, with each thread resuming from where it was paused at each clock tick.
Communication between threads is done using globally broadcast signals.
The communication between Esterel's threads is deterministic, i.e. a single signal cannot be read as both present and not present in any tick.
Esterel can, additionally, use \textit{pre()} (pre-emption) statements to check signals past presence, allowing for logical delays in the execution of an action.
Due to the structure of Esterel's loops, unbounded loops are not allowed; it must be guaranteed that a loop will be paused at least once per iteration.

Figure~\ref{fig:esterel-abro} shows the well known \textbf{ABRO} example by G. Berry.
This module has 3 defined input signals \textit{A}, \textit{B} and \textit{R} and one defined output signal \textit{O}.
Usually, a \textit{loop} denotes an iterative thread that repeats when the \textit{end loop} statement is reached, where each loop must include a \textit{pause}. 
However, execution of this loop only iterates when \textit{R} is detected; the loop resets at the beginning of the next clock tick when \textit{R} is detected.
When \textit{R} is not detected, the loop does not loop, but instead \textit{pauses} until \textit{R} is detected.
The \textit{loop <action> each R} can be alternatively written as \textit{loop [abort [<action> pause;] when R] end loop}, i.e. take some <action>, pause at the end of the <action>, and then wait for \textit{R} to repeat the loop.

The \textbf{||} are used to show parallel actions, i.e. concurrency.
This means that \textit{await A} and \textit{await B} are running concurrently, where \textit{await <signal>} is synonymous with ``pause until <signal> is present''.
The statement \textit{emit O} sets the output signal \textit{O} to be present for one clock cycle.

When combined, the statements in this example would combine to do the following, described in English for convenience:
Wait for A and B. 
When both A and B have been present, present O once.
As soon as R is present, start from the beginning.

\begin{figure}
	\begin{lstlisting}
	module ABRO:
	input A, B, R;
	output O;
	
	loop
	[ await A || await B ];
	emit O
	each R
	
	end module
	\end{lstlisting}
	\caption{Mono-periodic `layer by layer', $WCRT = l_i \odot l_h \odot l_o$}
	\label{fig:esterel-abro}
\end{figure}


\section{\acf{RE} of Autonomous Systems}
While static verification has its place, more dynamic approaches to verification and safety can be used to pick up anything that the static verification and testing may have missed.
Take a standard image classification \ac{CNN} for example.
The \ac{CNN} can be trained to 99.9\% accuracy according to the test cases used to train it.
However, this means that the \ac{CNN} fails 0.1\% of the time, and that is only on the tested population, not even taking the entire population into consideration.
Having a method to verify this \ac{CNN} while it is running and pick up any inevitable failures would allows for this \ac{CNN} to be used in systems where safety is critical.

\subsection{Runtime Enforcement}
% Runtime enforcement
\ac{RE} is a subset of \ac{RA} that focuses on formal semantics and blocking, delaying, modifying and/or re-ordering of events in a system. 
Processes that are deemed unsafe can be monitored by an enforcer at runtime to ensure that they obey desired policies and remain in a safe state at all times~\cite{theoryRE}. 
Formal runtime verification methodologies mathematically guarantee the detection of improper system behaviour \cite{RuntimeAssuranceForComplexCPS}.
For example, \ac{SA} have been proposed, which formally monitor uni-directional run-time properties only (e.g. outputs only)~\cite{enfsafepol}.
Edit automata are a type of \ac{SA} that can edit, suppress or insert events~\cite{editautomata}. 
\ac{DTA} have been proposed that can edit \textit{bi-directional} events at runtime~\cite{recps}. 
They were designed for reactive \acp{CPS} demonstrated in a pacemaker environment~\cite{recps}. 

An example of the placement of an enforcer, in this case a \ac{DTA}, in a \ac{CPS} is shown in Figure~\ref{fig:re} for an \acf{ESS}.
It shows that the enforcer sits between the plant and the controller, monitoring the inputs and outputs of the controller.
It will be able to detect unsafe inputs/outputs to/from the controller and allow the system to act in a safe manner.
\begin{figure}
	\centering
	\includegraphics[width=\textwidth]{Content/fig/ESS-RE.pdf}
	\caption{Example of \ac{RE} \label{fig:re}}
\end{figure}

\subsection{Runtime Enforcement of \acp{ANN}}
% Write about exisiting autonomous RE
The idea of \ac{RE} of autonomous systems is a researched topic. 
De Niz et. al. propose a type of \ac{RE} they term temporal enforcement, which ensures that the system controller meets timing deadlines where outputs are concerned~\cite{safe-enforce-auto}. 
While this shares similarities with the work in this paper, their work does not expand to cover \acp{ANN}, and does not propose the use of \ac{RE} for anything other than meeting timing deadlines.
Aniculaesei et. al. propose static formal verification and runtime monitoring of autonomous, robotic systems to prevent physical collisions during system execution~\cite{runtime-monitor}.
While this looks at the enforcement of system outputs, the inputs are not monitored and the timing deadlines of the system are not investigated. 
Additionally, the case study involves a robot controlled by an automaton, not a highly complex \ac{AI} such as an \ac{ANN}.





\section{Summary}
This chapter covers the basics of the concepts introduced in this thesis.

A description of what \acp{ANN} are, their functionality and their safety properties is given.
The structure of various \acp{ANN} is shown and briefly described.

The basics of synchronous programming is given, while Esterel is described in more detail.
A complete example of an Esterel program is given, with a description of how it works.

Finally, dynamic verification is discussed as a technique to verify autonomous systems.
\ac{RE} is introduced as a valid technique to dynamically verifying the properties of \ac{CPS}.
