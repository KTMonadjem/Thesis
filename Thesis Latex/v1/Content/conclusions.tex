In this thesis, we proposed the use of synchronous programming towards the safe use of \acp{ANN} in \acp{CPS}, which are safety-critical systems.
Using the synchronous programming language Esterel, \acp{SNN}, were developed to create \acp{ANN} that maintained synchronous semantics.
We were able to create fully synchronous, predictable \acp{ANN} that were able to be used as the controllers in all our benchmarks.
The synchronous approach to \acp{ANN}, which includes formal definitions of the \acp{ANN}, simulations and implementations of \ac{CPS}, was demonstrated throughout this thesis.
The results and concerns of this approach are discussed.

Two different structure types were defined: \acp{SNN} and \acp{MNN}.
\acp{SNN} are \acp{ANN} that run in a synchronous manner and maintain synchronous semantics, while \acp{MNN} are compositions of multiple \acp{SNN}, also retaining synchronous semantics.
Using the time predictable T-CREST platform, a set of benchmarks were developed using Esterel and C to prove the efficacy of \acp{SNN} and \acp{MNN}. 
These benchmarks ranged from basic, \acp{MLP} to larger, more complex \acp{MNN}.
Static timing analysis was done on these benchmarks, proving that the implemented \acp{SNN} and \acp{MNN} were not only time predictable, but also that the system were able to meet real-time deadlines.
Additionally, a Python tool chain, termed \ac{MNN2C} was introduced.
This compiler was able to produce time-predictable, \acp{MNN} from existing Keras trained \acp{ANN}.
This tool chain produced more accurate, lower \ac{WCRT} measurements compared to the original \acp{MNN}.
It was found that there were fluctuations in the measured run-time of \acp{ANN} however, generally, variation in run-time is cause by conditionals (branches) and \acp{ANN} do not contain conditionals.
Instead, this is due to several other factors, including the parallelization of tasks, caching, loops in execution and complex arithmetic. 
These differ every execution and result in varied run-time of the \acp{ANN}.

The next body of work introduced the concept of combining \ac{RE} with \acp{MNN}.
To this end, the definition of a \ac{MNN} was expanded to include arbitrary synchronous components, such as run-time enforcers, and not \acp{SNN}.
These new \acp{MNN} were termed \acp{SNN}.
An \ac{AV} case study was used to demonstrate the efficacy of run-time enforced \acp{SNN} by enforcing a set of safety policies to ensure the safe behaviour of an \ac{AV} when presented with dangerous situations.
This approach was shown to vastly increase the safety of an \ac{AV}, allowing the \ac{AV} to run autonomously for long periods of time.
However, a complication arose with the realisation that the I/O of an \ac{ANN} with complex inputs, such as a \ac{CNN}, cannot be enforced.

The issue of input perturbation, where the inputs to the system are altered beyond the control of the system, was addressed next.
We proposed the use of \ac{RV}, sensor fusion and \acp{SNN} to decrease the risk posed by input perturbation.
To show the effect of input perturbation, and test our approach to addressing it, a different \ac{AV} system was created. 
This system was a simulation of the object classifier in an \ac{AV}, i.e. the part of the controller responsible for identifying the \ac{AV}'s surrounding environment.
Perturbed inputs were shown to decrease the classification accuracy of the system by up to 50\%.
Our solution showed that \ac{RV} was able to ``catch'' more than 70\% of all misclassifications with perfect inputs, and when input perturbation occurred \ac{RV} was able to ``catch'' more than 80\% of the misclassifications.
Using the \ac{MNN2C} tool, this approach was tested on Keras generated \acp{SNN}.
These \acp{SNN} produced the same results, showing that more than 70\% of all misclassifications were detected by the \ac{RV}.

\section{Future Work}

While synchronous, time predictable \acp{ANN} proved to be of great value, they were only implemented and tested using C on single core processors.
Multi-core implementation and timing was not covered in this thesis, but was researched with the construction of \ac{MNN2C}.
More research is required on the efficient multi-core implementations of \acp{SNN} for embedded systems.
Additionally, the hardware implementation of \acp{SNN} was not researched for this thesis, but is also a key component of research.
\acp{SNN} have the potential to be implemented on a whole range of hardware, from \acp{FPGA} to graphics cards.
This needs to be carefully researched. 

This thesis suggested \ac{RE} as an approach to creating safe \acp{ANN}, however only a single run-time enforcer was used in each benchmark.
While this was shown to be largely effective, this is not the limit to which \ac{RE} can be used in these \acp{SNN}.
In this thesis, we did not fully examine the enforcement of multiple networks in a \ac{SNN}, nor did we fully investigate all the possible compositions and combinations of \ac{RE} and \acp{MNN}.
Examining more compositions of \acp{SNN} with their run-time enforcers could lead to more capable systems that are still safe, or safer. 
Approaches such as using \ac{RE} during the training of \acp{SNN} has yet to be explored, and \ac{RE} between layers of individual \acp{SNN} has also yet to be explored.

The ensembles used in Chapters 4 and 5 only used basic averaging functions to increase the accuracy of worst case trained \acp{ANN}.
With a more advanced averaging function, these ensembles could increase the classification accuracy of even the best trained \acp{ANN}.

Only the basics of \ac{RV} was discussed in this thesis.
\ac{RV} has a lot more value than just being used for \acp{CNN} in \ac{AV} systems.
This approach can be taken on any system where the inputs to the system are complex, such a intrusion detection system on networks. 
More benchmarks should be developed that expand on many more \ac{CPS} that could benefit from \ac{RV}.

Lastly, the composition of \acp{SNN} was not fully researched in this thesis.
The training phase of \acp{SNN} was skipped, instead each \ac{ANN} was trained individually.
\acp{SNN} are a unique composition of \acp{ANN} and other synchronous components, and the training of such systems needs further investigation.
Additionally, the only structure of \ac{SNN} used in this thesis was a \ac{SNN} ensemble, where each \ac{SNN} in the ensemble works with the others in the ensemble to provide more accurate output.
There exist endless ways that \acp{SNN} can be combined, and more of these ways should be implemented and tested.










