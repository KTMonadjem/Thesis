\section{Introduction}
\label{sec:intro}


\ignore{Motivate CPS systems such as autonomous vehicles that are AI
intensive. Most of the AI tasks are based on neural networks.
Briefly discussed the current status of neural networks and motivate
the need for formal methods. Discussed related work and then
the problem statement. Proposed solution \acp{SNN}.}

\acp{CPS} use a set of controllers that are distributed across a network for the 
control of physical processes~\cite{alur2015principles}. \ac{CPS} applications encompass real-time systems, where 
the system needs to satisfy a set of timing requirements to ensure correct operation. Examples include autonomous vehicles and
smart power grids. Here, a missed deadline may result in catastrophic consequences, making these \acp{CPS} highly 
\textit{safety-critical}. 

Increasingly, \acf{AI} based decision making is used in such safety-critical \ac{CPS}. 
This is of increasing concern since ``various machine learning algorithms can fail under small adversarial perturbations''~\cite{seshia2016towards}.
Considering this, \emph{formal methods}~\cite{clarke1999model} based techniques are recommended for the analysis of safety of the AI modules~\cite{russell2015}.
Formal verification is used to ensure that the system meets desired functional 
requirements expressed as temporal logic formulae~\cite{clarke1999model}.
While formal verification of hardware-software systems is a well developed area, such formal analysis of 
 \ac{AI} poses considerable challenges as outlined in~\cite{seshia2016towards}. \ignore{Key challenges are:
 (1) the system behaviour is environment dependent and the formal verification of such 
open systems is very complex~\cite{kupferman1996module}; (2) it is difficult to express properties formally; (3) the system is constantly evolving during the learning phases 
and the modelling of such systems is yet to be developed; and (4) scalable analysis techniques for \ac{AI} based \ac{CPS} are yet unknown.}

In this paper, we limit ourselves to \ac{AI}-based CPS, which use machine learning algorithms based on \acp{ANN}~\cite{yegnanarayana1994artificial}. 
This is since \ac{ANN}s, and their deep variants, like Convolutional Neural Networks (CNNs) ~\cite{schmidhuber2015deep}, 
%like~\acp{CNN}~\cite{schmidhuber2015deep},
are widely used in \ac{CPS} applications such as autonomous vehicles, e.g. in \cite{EndToEndLearningForSelfDrivingCars},
where a \ac{CNN} is trained to map raw pixel data directly to vehicle steering commands.
\ignore{Deep learning has been of immense interest, especially since it has been shown to work very 
well in key image and video processing tasks, which are at the core of process automation.} 

While considerable research effort is starting in the direction of formal verification of \ac{AI}-based \ac{CPS}~\cite{seshia2016towards, russell2015},
 the issue of timing verification has received scant attention. 
Like the challenges involving functional verification, timing verification of AI-based  \ac{CPS} poses considerable 
challenges due to the fact that: (1) real-time \ac{AI} systems could involve many concurrent and interacting \ac{AI} modules, which need 
deterministic composition for safety; (2) \ac{AI} modules are usually developed as untimed systems and the reactive nature of 
AI algorithms used in CPS are not carefully studied; and (3) \acf{WCET} analysis~\cite{wilhelm2008worst} of \ac{AI}-based \ac{CPS} has received scant attention.
 In the following section we 
 consider how \acp{ANN} capture timing information.


\subsection{ Modelling of time in \acp{ANN}}
\label{ANN-review}

\acp{ANN} were originally proposed to mimic the functioning of  biological neural networks~\cite{kohonen1988introduction}, which produce recurrent spatio-temporal patterns~\cite{rolston2007precisely}. 
Similar timed activity of neurons in the cerebellum has been reported in~\cite{bullock1994neural, moore1989adaptively}. 
A number of types of \ac{NN} which mimic their biological counterparts exist, varying in complexity and accuracy, including the Spiking Neural Network~\cite{izhikevich2003spiking,maass1997spiking}, which was designed to model the brain. %and has been demonstrated to be periodic and run with discrete time intervals when implemented in software. 

Most \acp{ANN} do not feature such complex models like those of Spiking Neural Network, as they are more difficult to use, implement, and train. 
Instead, they rely on simpler networks, which can be considered as \emph{un-timed non-linear} functions, 
where the outputs change relative to the inputs, but the timing of the change is not precisely defined. 
An example of such a network is provided in Figure~\ref{fig:mlp-ann}, which is using neurons defined in Figure~\ref{fig:artificial-neuron}. 
This is a type of \ac{NN} known as a \acf{MLP}~\cite{yegnanarayana1994artificial}.


%, it does not see as much use as an \acp{ANN} as it is much more difficult to use, implement and train. 
%However, since these \acp{SNN} directly model the neural structure of the brain, it can be shown that they are periodic and run on discrete time intervals when implemented in software. 
%While \acp{ANN} were developed to mimic their biological counterparts, the timing aspects were not captured.
%Consequently, an \ac{ANN} may be considered as a \emph{non-linear function}, where the outputs change relative to the 
%inputs but the timing of this change is not precisely defined. 

Specialised neural networks, called \acfp{RNN}~\cite{medsker2001recurrent}, were introduced  
 to classify temporal sequences. These operate in a step by step manner, where the operation in the current 
time step relies on the context from some previous step. Thus, \acp{RNN} may be viewed as a periodic networks, whose
 period is one. However, the 
use of such networks in \ac{CPS} is yet to be thoroughly investigated. Moreover, 
\acp{RNN} and their compositions are not formalised especially from the point of view of designing timed AI 
systems used in \ac{CPS}. This motivates our proposal for a new class of \acp{ANN}, we term \acfp{SNN}, introduced in the next section.
In particular, with current design methodologies, a deep neural network like a \ac{CNN} may take long time 
to produce its output given a new set of inputs i.e. due to the intensive computation, the response time may be slow. 

This chapter presents a formal methodology for the design of timed neural networks to address this issue.
Using a variety of execution approaches, presented in  Section~\ref{sec:esterel-mapping}, we illustrate through a number
of examples how \ac{CPS} can be designed using \ac{ANN} while still remaining responsive to critical events even during lengthy computations.
% and illustrated through the \acf{ESS} case study in 
%Section~\ref{sec:results}. This approach is developed so that the \ac{CPS} remains responsive to critical events 
% while a \ac{CNN} may be performing a lengthy computation.
%\todo{We also show that a \ac{RNN} is a special instance of a \ac{SNN}.}

%Even where time has been included, such as in  \acfp{RNN}~\cite{medsker2001recurrent}, which are 
%designed to classify temporal sequences, they are simple, and operate in a step by step manner, where the operation in the current 
%time step relies on the context from the previous step. However, to be effective in \ac{CPS} they lack two key ingredients: they 
%need to operate in a reactive manner to capture the reactive nature of \ac{CPS} and they need to operate concurrently to 
%capture many concurrently interacting neural networks. This motivates our proposal for a new class of \ac{ANN} we
%term \acp{SNN} introduced in the next section.

The key contributions of the chapter are: (1) \acfp{SNN} as a model for designing periodic 
AI modules, where the length of the period is fixed and the number of cycles are application dependent.
We show that existing neural networks, such as \ac{MLP}, are special instances of \ac{SNN};
(2) we provide synchronous execution semantics of \acp{SNN} by providing a mapping to the 
Esterel synchronous programming language. This provides operators for sound and causal composition~\cite{benveniste2003synchronous} to 
create seamless compositions of interacting neural networks for the first time; (3) we develop a 
timed semantics of such compositions using \ac{WCRT}-algebra~\cite{wang2017timing}; (4) we
 develop an approach for designing machine learning applications using \acp{SNN}, which are amenable to
  static \acf{WCRT} analysis~\cite{roop2009tight}, for the first time; and (5) we propose a ``layer-by-layer'' approach of 
 designing \acp{SNN} so as to minimise the \ac{WCRT}, in order to meet the desired response to 
critical events, while meeting the overall response time requirement of a given \ac{SNN}. 



