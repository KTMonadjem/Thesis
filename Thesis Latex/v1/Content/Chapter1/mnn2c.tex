\section{\acf{MNN2C}}
\label{sec:mnn2c}
\acfp{MBD} is a traditional approach to designing systems~\cite{dmd2019}.
As opposed to design by trial-and-error, \ac{MBD} builds formally defined, safer systems~\cite{dmd2019}.
This approach to creating systems is highly preferred where the safety of the system, e.g. systems that interact with humans, is concerned.
This is relevance where \ac{AI} systems are created that interact with the same environment as humans, such as the \acf{ESS} shown in Section~\ref{sec:ess}.

The ability to generate formally defined system models from existing \acp{ANN} allows for potentially unsafe and unpredictable \acp{ANN} to be re-implemented in such a way that they are safe and predictable.
This allows the use of such \acp{ANN} in systems were safety is critical, e.g. \acfp{CPS}.

Keras~\cite{chollet2015keras} is an \ac{ANN} Python library, able to use TensorFlow as a backend. 
Keras enables the quick, easy and highly adaptable training of various \acp{ANN}.
The \acp{ANN} generated by Keras are not safe: they are not formally defined, and any timing must be done using measurement based timing. 
This poses a problem to the use of the \acp{ANN} in \ac{CPS}, since \ac{CPS} have strict rules and protocols that the software must follow.

\acf{MNN2C} is an \ac{ANN} compiler that aims to produce \acf{MNN} models in C using pre-existing, Keras-trained \acp{ANN}.
The C code that \ac{MNN2C} produces is not only time-predictable, but the generated \acp{MNN} are also formally defined in \ref{def:snn}.
This means that the \ac{MNN} models generated can be used in \ac{CPS} with the knowledge that these \acp{MNN} are rigorously, mathematically defined. 
Additionally, \ac{MNN2C} allows for the simple, easy and quick training of \acp{ANN} which can then be implemented in existing C systems.

\subsection{Results}
The software generated by \ac{MNN2C} was not only highly accurate, with a correlation coefficient of 1.0 compared to the original Keras generated \ac{ANN}, but also had a lower static \ac{WCET} compared to the code originally created in this chapter.
Using the built-in \ac{WCET} compiler, the timing results were easily found for each time-predictable example from Table~\ref{tbl:res-sann} and are shown in Table~\ref{tbl:res-mnn2c}.
This table shows that the structure of the \ac{MNN} being analysed has a large influence on the timing properties of that \ac{ANN}. 
The \ac{ESS} \ac{MNN}, which has a lot fewer non-linear activation functions (using a lot of Re-Lu activations compared to Tanh) has a much larger decrease in \ac{WCET} compared to the other benchmarks, which average a 26\% decrease.
This shows that the \acp{MNN} generated by \ac{MNN2C} better manage the implementation of the activation functions it uses, giving more accurate \ac{WCET} of the \ac{MNN}.

\begin{table}[H]
	\centering
	\caption{MNN2C Static \ac{WCRT} results for \texttt{ESS}, \texttt{AI-BRO}, \texttt{XOR} and \texttt{ADDER}}
	\label{tbl:res-mnn2c}
	\begin{tabular}{|p{0.2\textwidth}|p{0.2\textwidth}|p{0.2\textwidth}|p{0.2\textwidth}|}
		\hline
		Benchmark         & Original Black-box WCRT (ms) & MNN2C Black-box WCRT (ms)  &  \% \textbf{decrease} \\ \hline
		\texttt{ESS}        & 14 & 4.41 & 68.5 \\  \hline
		\texttt{AI-BRO}        & 2.8 & 2.29 & 18.21 \\ \hline
		\texttt{XOR}        & 0.82 & 0.53 & 35.37 \\  \hline
		\texttt{ADDER}        & 0.49 & 0.37 & 24.49 \\ \hline
	\end{tabular}
\end{table}

\subsection{Future Work}
\ac{MNN2C} currently only generates time predictable, formally defined C code \acp{ANN} based off of Keras \acp{ANN}.
While this is a huge step, this is not the limit when it comes to using \acp{ANN}.
\ac{MNN2C} can be expanded to generate code that is implementable on various hardware platforms, such as \acp{FPGA}, graphics cards and many others.
This would allow for the implementation of \acp{ANN} in various \ac{CPS} besides those that just use C software.







